from typing import Any, TypedDict
from langchain.agents import AgentExecutor, create_openai_tools_agent
from llms import get_llm
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
import os

from langgraph.graph import StateGraph, END
from dotenv import load_dotenv
from chains import get_finish_chain, get_supervisor_chain
from tools import (
    get_job_search_tool,
    ResumeExtractorTool,
    generate_letter_for_specific_job,
    get_google_search_results, 
    save_cover_letter_for_specific_job,
    scrape_website,
)
from prompts import (
    get_analyzer_agent_prompt_template,
    get_search_agent_prompt_template,
    get_generator_agent_prompt_template,
    researcher_agent_prompt_template,
)

load_dotenv()


def create_agent(llm, tools: list, system_prompt: str):
    """
    Creates an agent using the specified ChatOpenAI model, tools, and system prompt.

    Args:
        llm : LLM to be used to create the agent.
        tools (list): The list of tools to be given to the worker node.
        system_prompt (str): The system prompt to be used in the agent.

    Returns:
        AgentExecutor: The executor for the created agent.
    """
    # Each worker node will be given a name and some tools.
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system",system_prompt,),
            MessagesPlaceholder(variable_name="messages"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ]
    )
    agent = create_openai_tools_agent(llm, tools, prompt)
    executor = AgentExecutor(agent=agent, tools=tools)
    return executor


def init_chat_model(model, model_provider, dashscope_api_key, temperature):
    return get_llm(
        provider=model_provider,
        model=model,
        api_key=dashscope_api_key,
        temperature=temperature,
    )

def supervisor_node(state):
    """
    Supervisor èŠ‚ç‚¹ - æ”¯æŒå¤šAgentåä½œ
    """
    chat_history = state.get("messages", [])
    user_query = state.get("user_input", "")
    
    # ğŸ”´ å¦‚æœæœ‰åç»­ä»»åŠ¡ï¼Œç›´æ¥æ‰§è¡Œ
    if state.get("needs_followup"):
        next_action = state["needs_followup"]
        state["needs_followup"] = ""  # æ¸…é™¤åç»­ä»»åŠ¡æ ‡è®°
        print(f"ğŸ”„ æ‰§è¡Œåç»­ä»»åŠ¡: {next_action}")
        state["next_step"] = next_action
        return state
    
    llm = init_chat_model(
        model=state["config"]["model"],
        model_provider=state["config"]["model_provider"],
        dashscope_api_key=state["config"].get("DASHSCOPE_API_KEY") or os.environ.get("DASHSCOPE_API_KEY"),
        temperature=state["config"].get("temperature", 0.3)
    )
    
    if not chat_history:
        chat_history.append(HumanMessage(content=user_query))
    
    # ğŸ”´ åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œæ£€æµ‹å¤åˆä»»åŠ¡
    user_lower = user_query.lower()
    
    # ğŸ”´ æ£€æµ‹å¤åˆä»»åŠ¡æ¨¡å¼
    if ("ç®€å†" in user_lower or "resume" in user_lower) and ("æ±‚èŒä¿¡" in user_lower or "cover letter" in user_lower):
        # å¤åˆä»»åŠ¡1ï¼šç®€å†åˆ†æ + æ±‚èŒä¿¡ç”Ÿæˆ
        print("ğŸ¯ æ£€æµ‹åˆ°å¤åˆä»»åŠ¡ï¼šç®€å†åˆ†æ + æ±‚èŒä¿¡ç”Ÿæˆ")
        state["needs_followup"] = "CoverLetterGenerator"
        next_action = "ResumeAnalyzer"
        
    elif ("ç®€å†" in user_lower or "resume" in user_lower or "åˆ†ææˆ‘çš„" in user_lower) and \
         ("å²—ä½" in user_lower or "job" in user_lower or "èŒä½" in user_lower or "æ¨è" in user_lower or "æ‹›è˜" in user_lower or "å·¥ä½œ" in user_lower):
        # ğŸ”´ å¤åˆä»»åŠ¡2ï¼šç®€å†åˆ†æ + å²—ä½æ¨è
        print("ğŸ¯ æ£€æµ‹åˆ°å¤åˆä»»åŠ¡ï¼šç®€å†åˆ†æ + å²—ä½æ¨è")
        state["needs_followup"] = "JobSearcher"
        next_action = "ResumeAnalyzer"
        
    elif ("æœç´¢" in user_lower or "æŸ¥æ‰¾" in user_lower) and \
         ("å²—ä½" in user_lower or "job" in user_lower or "èŒä½" in user_lower or "å·¥ä½œ" in user_lower) and \
         ("ç®€å†" in user_lower or "resume" in user_lower or "æˆ‘çš„" in user_lower):
        # ğŸ”´ å¤åˆä»»åŠ¡3ï¼šç®€å†åˆ†æ + å²—ä½æœç´¢
        print("ğŸ¯ æ£€æµ‹åˆ°å¤åˆä»»åŠ¡ï¼šç®€å†åˆ†æ + å²—ä½æœç´¢")
        state["needs_followup"] = "JobSearcher"
        next_action = "ResumeAnalyzer"
        
    else:
        # å•ä¸€ä»»åŠ¡ï¼Œä½¿ç”¨ supervisor chain
        supervisor_chain = get_supervisor_chain(llm)
        output = supervisor_chain.invoke({"messages": chat_history})
        next_action = output.content.strip()
        
        # éªŒè¯è¾“å‡º
        valid_agents = ["ResumeAnalyzer", "CoverLetterGenerator", "JobSearcher", "WebResearcher", "ChatBot", "Finish"]
        if next_action not in valid_agents:
            if any(word in user_lower for word in ["ç®€å†", "resume", "åˆ†æ"]):
                next_action = "ResumeAnalyzer"
            elif any(word in user_lower for word in ["å²—ä½", "job", "å·¥ä½œ"]):
                next_action = "JobSearcher"
            elif any(word in user_lower for word in ["æ±‚èŒä¿¡", "cover letter"]):
                next_action = "CoverLetterGenerator"
            elif any(word in user_lower for word in ["æœç´¢", "ç ”ç©¶", "æ–°é—»"]):
                next_action = "WebResearcher"
            else:
                next_action = "ChatBot"
    
    print(f"ğŸ¯ Supervisor è·¯ç”±åˆ°: {next_action}")
    state["next_step"] = next_action
    state["messages"] = chat_history
    return state

def resume_analyzer_node(state):
    """
    ç®€å†åˆ†æèŠ‚ç‚¹ - æ”¯æŒåä½œæ¨¡å¼
    """
    llm = init_chat_model(
        model=state["config"]["model"],
        model_provider=state["config"]["model_provider"],
        dashscope_api_key=state["config"].get("DASHSCOPE_API_KEY") or os.environ.get("DASHSCOPE_API_KEY"),
        temperature=state["config"].get("temperature", 0.3)
    )
    
    analyzer_agent = create_agent(
        llm, [ResumeExtractorTool(), get_google_search_results], 
        get_analyzer_agent_prompt_template()
    )
    
    state["callback"].write_agent_name("ğŸ“„ ResumeAnalyzer Agent")
    
    output = analyzer_agent.invoke(
        {"messages": state["messages"]}, 
        {"callbacks": [state["callback"]]}
    )
    
    result_content = output.get("output")
    state["messages"].append(AIMessage(content=result_content, name="ResumeAnalyzer"))
    
    # ğŸ”´ å¦‚æœæœ‰åç»­ä»»åŠ¡ï¼Œæ ‡è®°ä¸ºæœªå®Œæˆ
    if state.get("needs_followup"):
        state["task_completed"] = False
        print("ğŸ“„ ç®€å†åˆ†æå®Œæˆï¼Œå‡†å¤‡æ‰§è¡Œåç»­ä»»åŠ¡...")
    else:
        state["task_completed"] = True
        print("ğŸ“„ ç®€å†åˆ†æå®Œæˆ")
    
    return state

def cover_letter_generator_node(state):
    """
    æ±‚èŒä¿¡ç”ŸæˆèŠ‚ç‚¹ - å¢å¼ºåä½œåŠŸèƒ½
    """
    llm = init_chat_model(
        model=state["config"]["model"],
        model_provider=state["config"]["model_provider"],
        dashscope_api_key=state["config"].get("DASHSCOPE_API_KEY") or os.environ.get("DASHSCOPE_API_KEY"),
        temperature=state["config"].get("temperature", 0.3)
    )
    
    generator_agent = create_agent(
        llm, [
            generate_letter_for_specific_job,
            save_cover_letter_for_specific_job,
            ResumeExtractorTool(),
        ], 
        get_generator_agent_prompt_template()
    )

    state["callback"].write_agent_name("âœï¸ CoverLetterGenerator Agent")
    
    # ğŸ”´ æ£€æŸ¥æ˜¯å¦æœ‰ç®€å†åˆ†æç»“æœï¼Œå¦‚æœæœ‰åˆ™ç”Ÿæˆæ›´å¥½çš„æç¤º
    messages_to_use = state["messages"].copy()
    
    # æŸ¥æ‰¾ ResumeAnalyzer çš„è¾“å‡º
    resume_analysis = None
    for msg in reversed(state["messages"]):
        if hasattr(msg, 'name') and msg.name == "ResumeAnalyzer":
            resume_analysis = msg.content
            break
    
    if resume_analysis:
        enhanced_prompt = f"""åŸºäºä»¥ä¸‹ç®€å†åˆ†æç»“æœï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„æ±‚èŒä¿¡ï¼š

**ç®€å†åˆ†æç»“æœï¼š**
{resume_analysis}

è¯·æ ¹æ®ä¸Šè¿°ç®€å†åˆ†æï¼Œç”Ÿæˆä¸€ä»½ä¸ªæ€§åŒ–çš„æ±‚èŒä¿¡ï¼Œçªå‡ºå€™é€‰äººçš„å…³é”®æŠ€èƒ½å’Œä¼˜åŠ¿ã€‚"""
        
        messages_to_use.append(HumanMessage(content=enhanced_prompt))
        print("âœï¸ ä½¿ç”¨ç®€å†åˆ†æç»“æœç”Ÿæˆæ±‚èŒä¿¡")
    
    output = generator_agent.invoke(
        {"messages": messages_to_use}, 
        {"callbacks": [state["callback"]]}
    )
    
    result_content = output.get("output")
    
    # ğŸ”´ å¦‚æœæ˜¯åä½œä»»åŠ¡çš„ç»“æœï¼Œæ·»åŠ è¯´æ˜
    if resume_analysis:
        final_result = f"""âœï¸ **åŸºäºç®€å†åˆ†æçš„ä¸ªæ€§åŒ–æ±‚èŒä¿¡**

{result_content}

---
*æ­¤æ±‚èŒä¿¡åŸºäºæ‚¨çš„ç®€å†åˆ†æç»“æœç”Ÿæˆï¼Œç¡®ä¿ä¸æ‚¨çš„èƒŒæ™¯å’ŒæŠ€èƒ½é«˜åº¦åŒ¹é…*"""
    else:
        final_result = result_content
    
    state["messages"].append(AIMessage(content=final_result, name="CoverLetterGenerator"))
    state["task_completed"] = True
    print("âœï¸ æ±‚èŒä¿¡ç”Ÿæˆå®Œæˆ")
    
    return state

def job_search_node(state):
    """
    èŒä½æœç´¢èŠ‚ç‚¹ - æ”¯æŒåä½œæ¨¡å¼
    """
    llm = init_chat_model(
        model=state["config"]["model"],
        model_provider=state["config"]["model_provider"],
        dashscope_api_key=state["config"].get("DASHSCOPE_API_KEY") or os.environ.get("DASHSCOPE_API_KEY"),
        temperature=state["config"].get("temperature", 0.3)
    )
    
    search_agent = create_agent(
        llm, [get_job_search_tool(), get_google_search_results], 
        get_search_agent_prompt_template()
    )
    
    state["callback"].write_agent_name("ğŸ’¼ JobSearcher Agent")
    
    # ğŸ”´ æ£€æŸ¥æ˜¯å¦æœ‰ç®€å†åˆ†æç»“æœï¼Œå¦‚æœæœ‰åˆ™ç”Ÿæˆæ›´å¥½çš„æœç´¢æç¤º
    messages_to_use = state["messages"].copy()
    
    # æŸ¥æ‰¾ ResumeAnalyzer çš„è¾“å‡º
    resume_analysis = None
    for msg in reversed(state["messages"]):
        if hasattr(msg, 'name') and msg.name == "ResumeAnalyzer":
            resume_analysis = msg.content
            break
    
    if resume_analysis:
        enhanced_prompt = f"""åŸºäºä»¥ä¸‹ç®€å†åˆ†æç»“æœï¼Œæœç´¢å’Œæ¨èåˆé€‚çš„å²—ä½ï¼š

**ç®€å†åˆ†æç»“æœï¼š**
{resume_analysis}

è¯·æ ¹æ®ä¸Šè¿°ç®€å†åˆ†æï¼Œæœç´¢åŒ¹é…çš„å²—ä½æœºä¼šï¼Œé‡ç‚¹å…³æ³¨ï¼š
1. ä¸å€™é€‰äººæŠ€èƒ½åŒ¹é…çš„èŒä½
2. é€‚åˆå€™é€‰äººç»éªŒæ°´å¹³çš„å²—ä½
3. å€™é€‰äººæ‰€åœ¨è¡Œä¸šæˆ–ç›¸å…³è¡Œä¸šçš„æœºä¼š
4. æä¾›å…·ä½“çš„å²—ä½åˆ—è¡¨å’Œç”³è¯·å»ºè®®"""
        
        messages_to_use.append(HumanMessage(content=enhanced_prompt))
        print("ğŸ’¼ ä½¿ç”¨ç®€å†åˆ†æç»“æœæœç´¢åŒ¹é…å²—ä½")
    
    output = search_agent.invoke(
        {"messages": messages_to_use}, 
        {"callbacks": [state["callback"]]}
    )
    
    result_content = output.get("output")
    
    # ğŸ”´ å¦‚æœæ˜¯åä½œä»»åŠ¡çš„ç»“æœï¼Œæ·»åŠ è¯´æ˜
    if resume_analysis:
        final_result = f"""ğŸ’¼ **åŸºäºç®€å†åˆ†æçš„ä¸ªæ€§åŒ–å²—ä½æ¨è**

{result_content}

---
*æ­¤å²—ä½æ¨èåŸºäºæ‚¨çš„ç®€å†åˆ†æç»“æœç”Ÿæˆï¼Œç¡®ä¿ä¸æ‚¨çš„æŠ€èƒ½å’Œç»éªŒé«˜åº¦åŒ¹é…*"""
    else:
        final_result = result_content
    
    state["messages"].append(AIMessage(content=final_result, name="JobSearcher"))
    state["task_completed"] = True
    print("ğŸ’¼ å²—ä½æœç´¢å®Œæˆ")
    
    return state

def web_research_node(state):
    """
    ç½‘ç»œç ”ç©¶èŠ‚ç‚¹ - æ”¯æŒåä½œæ¨¡å¼
    """
    llm = init_chat_model(
        model=state["config"]["model"],
        model_provider=state["config"]["model_provider"],
        dashscope_api_key=state["config"].get("DASHSCOPE_API_KEY") or os.environ.get("DASHSCOPE_API_KEY"),
        temperature=state["config"].get("temperature", 0.3)
    )
    
    research_agent = create_agent(
        llm, [get_google_search_results, scrape_website], 
        researcher_agent_prompt_template()
    )
    
    state["callback"].write_agent_name("ğŸ” WebResearcher Agent")
    
    output = research_agent.invoke(
        {"messages": state["messages"]}, 
        {"callbacks": [state["callback"]]}
    )
    
    state["messages"].append(AIMessage(content=output.get("output"), name="WebResearcher"))
    state["task_completed"] = True
    return state

def chatbot_node(state):
    """èŠå¤©æœºå™¨äººèŠ‚ç‚¹"""
    llm = init_chat_model(
        model=state["config"]["model"],
        model_provider=state["config"]["model_provider"],
        dashscope_api_key=state["config"].get("DASHSCOPE_API_KEY") or os.environ.get("DASHSCOPE_API_KEY"),
        temperature=state["config"].get("temperature", 0.3)
    )
    
    state["callback"].write_agent_name("ğŸ¤– ChatBot Agent")
    
    finish_chain = get_finish_chain(llm)
    output = finish_chain.invoke({"messages": state["messages"]})
    
    state["messages"].append(AIMessage(content=output.content, name="ChatBot"))
    state["task_completed"] = True
    return state

def define_graph():
    """
    å®šä¹‰æ”¯æŒå¤šAgentåä½œçš„å·¥ä½œæµå›¾
    """
    workflow = StateGraph(AgentState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("Supervisor", supervisor_node)
    workflow.add_node("ResumeAnalyzer", resume_analyzer_node)
    workflow.add_node("JobSearcher", job_search_node)
    workflow.add_node("CoverLetterGenerator", cover_letter_generator_node)
    workflow.add_node("WebResearcher", web_research_node)
    workflow.add_node("ChatBot", chatbot_node)
    
    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("Supervisor")
    
    # Supervisor çš„æ¡ä»¶è·¯ç”±
    workflow.add_conditional_edges(
        "Supervisor",
        lambda x: x["next_step"],
        {
            "ResumeAnalyzer": "ResumeAnalyzer",
            "JobSearcher": "JobSearcher", 
            "CoverLetterGenerator": "CoverLetterGenerator",
            "WebResearcher": "WebResearcher",
            "ChatBot": "ChatBot",
            "Finish": END
        }
    )
    
    # ğŸ”´ å…³é”®æ”¹åŠ¨ï¼šAgent å®Œæˆåçš„è·¯ç”±é€»è¾‘
    def should_continue(state):
        """å†³å®šAgentæ‰§è¡Œå®Œæˆåæ˜¯å¦ç»§ç»­"""
        if state.get("task_completed", True):
            return "END"
        else:
            return "CONTINUE"
    
    # Agent æ‰§è¡Œå®Œæˆåçš„æ¡ä»¶è·¯ç”±
    for agent in ["ResumeAnalyzer", "JobSearcher", "CoverLetterGenerator", "WebResearcher", "ChatBot"]:
        workflow.add_conditional_edges(
            agent,
            should_continue,
            {
                "END": END,
                "CONTINUE": "Supervisor"  # ğŸ”´ å›åˆ° Supervisor ç»§ç»­åä½œ
            }
        )
    
    return workflow.compile()

# The agent state is the input to each node in the graph
class AgentState(TypedDict):
    user_input: str              # ç”¨æˆ·è¾“å…¥
    messages: list[BaseMessage]  # å¯¹è¯å†å²
    next_step: str               # ä¸‹ä¸€æ­¥æ‰§è¡Œçš„Agent
    config: dict                 # é…ç½®ä¿¡æ¯
    callback: Any                # å›è°ƒå¤„ç†å™¨
    task_completed: bool         # ğŸ”´ æ–°å¢ï¼šæ ‡è®°ä»»åŠ¡æ˜¯å¦å®Œæˆ
    needs_followup: str          # ğŸ”´ æ–°å¢ï¼šéœ€è¦åç»­æ‰§è¡Œçš„Agent