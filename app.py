from typing import Callable, TypeVar
import os
import inspect
import streamlit as st
import streamlit_analytics2 as streamlit_analytics
from dotenv import load_dotenv
from streamlit_chat import message
from streamlit_pills import pills
from streamlit.runtime.scriptrunner import add_script_run_ctx, get_script_run_ctx
from streamlit.delta_generator import DeltaGenerator
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from custom_callback_handler import CustomStreamlitCallbackHandler
from agents import define_graph
import shutil
from langchain_core.messages import HumanMessage, AIMessage

load_dotenv()

# ä»Streamlit secretsæˆ–.envè®¾ç½®ç¯å¢ƒå˜é‡
os.environ["LINKEDIN_EMAIL"] = st.secrets.get("LINKEDIN_EMAIL", "")
os.environ["LINKEDIN_PASS"] = st.secrets.get("LINKEDIN_PASS", "")
os.environ["LANGCHAIN_API_KEY"] = st.secrets.get("LANGCHAIN_API_KEY", "")
os.environ["LANGCHAIN_TRACING_V2"] = os.getenv("LANGCHAIN_TRACING_V2") or st.secrets.get("LANGCHAIN_TRACING_V2", "")
os.environ["LANGCHAIN_PROJECT"] = st.secrets.get("LANGCHAIN_PROJECT", "")
os.environ["SERPER_API_KEY"] = st.secrets.get("SERPER_API_KEY", "")
os.environ["FIRECRAWL_API_KEY"] = st.secrets.get("FIRECRAWL_API_KEY", "")
os.environ["LINKEDIN_SEARCH"] = st.secrets.get("LINKEDIN_JOB_SEARCH", "")
os.environ["DASHSCOPE_API_KEY"] = st.secrets.get("DASHSCOPE_API_KEY", "")

# é¡µé¢é…ç½®
st.set_page_config(layout="wide")
st.title("JobPilot èŒä¸šåŠ©æ‰‹ - ğŸ‘¨â€ğŸ’¼")
st.markdown("[è”ç³»ä½œè€… QQ é‚®ç®±](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=V2RmYmRjZm9mbmIXJiZ5NDg6)")

streamlit_analytics.start_tracking()

# ğŸ”´ ä¼˜åŒ–ï¼šç®€åŒ–ç›®å½•å’Œè·¯å¾„è®¾ç½®
temp_dir = "temp"
dummy_resume_path = os.path.abspath("dummy_resume.pdf")

if not os.path.exists(temp_dir):
    os.makedirs(temp_dir)


uploaded_document = st.sidebar.file_uploader("ä¸Šä¼ ä½ çš„ç®€å†ï¼ˆPDFï¼‰", type="pdf")

# ğŸ”´ ä¼˜åŒ–ï¼šç®€åŒ–ç®€å†å¤„ç†é€»è¾‘
if not uploaded_document:
    # æ£€æŸ¥æ˜¯å¦æœ‰æ¼”ç¤ºç®€å†
    if os.path.exists(dummy_resume_path):
        uploaded_document = open(dummy_resume_path, "rb")
        st.sidebar.write("æœªä¸Šä¼ ç®€å†ï¼Œæ­£åœ¨ä½¿ç”¨æ¼”ç¤ºç®€å†ã€‚")
        st.sidebar.markdown(f"[æŸ¥çœ‹æ¼”ç¤ºç®€å†]({'https://drive.google.com/file/d/1vTdtIPXEjqGyVgUgCO6HLiG9TSPcJ5eM/view?usp=sharing'})")
    else:
        st.sidebar.write("ğŸ“ è¯·ä¸Šä¼ æ‚¨çš„ç®€å†ä»¥å¼€å§‹ä½¿ç”¨èŒä¸šåŠ©æ‰‹åŠŸèƒ½")
        uploaded_document = None
        
# ğŸ”´ ä¼˜åŒ–ï¼šé¿å…é‡å¤ä¿å­˜ç®€å†
if uploaded_document:
    # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°æ–‡ä»¶
    current_filename = getattr(uploaded_document, 'name', 'dummy_resume.pdf')
    if not st.session_state.get("resume_saved", False) or st.session_state.get("resume_filename", "") != current_filename:
        bytes_data = uploaded_document.read()
        filepath = os.path.join(temp_dir, "resume.pdf")
        with open(filepath, "wb") as f:
            f.write(bytes_data)
        
        # æ›´æ–°ä¼šè¯çŠ¶æ€
        st.session_state["resume_saved"] = True
        st.session_state["resume_filename"] = current_filename
        
        print(f"æ–°ç®€å†å·²ä¿å­˜: {current_filename}, ç®€å†å·²ä¿å­˜åˆ°: {filepath}, å¤§å°: {len(bytes_data)} bytes")
        st.sidebar.markdown("**âœ… ç®€å†ä¸Šä¼ æˆåŠŸï¼**")
    else:
        st.sidebar.markdown(f"**âœ… å·²åŠ è½½ç®€å†ï¼š{current_filename}**")

# é€šä¹‰åƒé—®é…ç½®
if st.secrets.get("DASHSCOPE_API_KEY", ""):
    st.sidebar.markdown("âœ… å·²ä»é…ç½®ä¸­åŠ è½½ DashScope API å¯†é’¥")
    api_key_tongyi = st.secrets.get("DASHSCOPE_API_KEY", "")
else:
    api_key_tongyi = st.sidebar.text_input(
        "DashScopeï¼ˆé€šä¹‰åƒé—®ï¼‰API å¯†é’¥",
        st.session_state.get("DASHSCOPE_API_KEY", ""),
        type="password",
    )

model_tongyi = st.sidebar.selectbox(
    "é€‰æ‹©é€šä¹‰åƒé—®æ¨¡å‹",
    ("qwen-turbo", "qwen-plus", "qwen-max", "qwen-max-1201"),
    help="æ¨èä½¿ç”¨ qwen-plus æˆ– qwen-max ä»¥è·å¾—æ›´å¥½çš„å·¥å…·è°ƒç”¨æ”¯æŒ"
)

settings = {
    "model": model_tongyi,
    "model_provider": "tongyi",
    "temperature": 0.3,
    "DASHSCOPE_API_KEY": api_key_tongyi,
}
st.session_state["DASHSCOPE_API_KEY"] = api_key_tongyi
os.environ["DASHSCOPE_API_KEY"] = api_key_tongyi

# ğŸ”´ ä¼˜åŒ–ï¼šæ·»åŠ åŠŸèƒ½çŠ¶æ€æ˜¾ç¤ºï¼Œå‚è€ƒapp copy.pyçš„ä¾§è¾¹æ ä¿¡æ¯
st.sidebar.markdown("### ğŸ› ï¸ åŠŸèƒ½çŠ¶æ€")
if st.secrets.get("SERPER_API_KEY", ""):
    st.sidebar.markdown("âœ… SerpAPI æœç´¢åŠŸèƒ½å·²å¯ç”¨")
else:
    st.sidebar.markdown("âš ï¸ SerpAPI æœªé…ç½®ï¼Œæœç´¢åŠŸèƒ½å—é™")

if st.secrets.get("FIRECRAWL_API_KEY", ""):
    st.sidebar.markdown("âœ… FireCrawl ç½‘é¡µæŠ“å–å·²å¯ç”¨")
else:
    st.sidebar.markdown("âš ï¸ FireCrawl æœªé…ç½®ï¼Œç½‘é¡µæŠ“å–å—é™")

if model_tongyi in ["qwen-plus", "qwen-max", "qwen-max-1201"]:
    st.sidebar.markdown("âœ… æ”¯æŒé«˜çº§å·¥å…·è°ƒç”¨åŠŸèƒ½")
else:
    st.sidebar.markdown("âš ï¸ åŸºç¡€æ¨¡å‹ï¼Œéƒ¨åˆ†é«˜çº§åŠŸèƒ½å¯èƒ½å—é™")

# åˆ›å»ºä»£ç†æµç¨‹
flow_graph = define_graph()
message_history = StreamlitChatMessageHistory()

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å˜é‡
if "active_option_index" not in st.session_state:
    st.session_state["active_option_index"] = None
if "interaction_history" not in st.session_state:
    st.session_state["interaction_history"] = []
if "response_history" not in st.session_state:
    st.session_state["response_history"] = ["ä½ å¥½ï¼è¯·é—®ä½ éœ€è¦ä»€ä¹ˆå¸®åŠ©?"]
if "user_query_history" not in st.session_state:
    st.session_state["user_query_history"] = ["ä½ å¥½! ğŸ‘‹"]
if "resume_saved" not in st.session_state:
    st.session_state["resume_saved"] = False
if "resume_filename" not in st.session_state:
    st.session_state["resume_filename"] = ""
if "DASHSCOPE_API_KEY" not in st.session_state:
    st.session_state["DASHSCOPE_API_KEY"] = ""

# èŠèŠç•Œé¢çš„å®¹å™¨
conversation_container = st.container()
input_section = st.container()

def initialize_callback_handler(main_container: DeltaGenerator):
    V = TypeVar("V")

    def wrap_function(func: Callable[..., V]) -> Callable[..., V]:
        context = get_script_run_ctx()

        def wrapped(*args, **kwargs) -> V:
            add_script_run_ctx(ctx=context)
            return func(*args, **kwargs)

        return wrapped

    streamlit_callback_instance = CustomStreamlitCallbackHandler(
        parent_container=main_container
    )

    for method_name, method in inspect.getmembers(
        streamlit_callback_instance, predicate=inspect.ismethod
    ):
        setattr(streamlit_callback_instance, method_name, wrap_function(method))

    return streamlit_callback_instance

# ğŸ”´ ä¼˜åŒ–ï¼šç®€åŒ–å¯¹è¯æ‰§è¡Œé€»è¾‘
def execute_chat_conversation(user_input, graph):
    callback_handler_instance = initialize_callback_handler(st.container())
    callback_handler = callback_handler_instance
    try:
        print(f"æ‰§è¡Œå¯¹è¯ï¼Œç”¨æˆ·è¾“å…¥: {user_input}")
        
        # æ¸…é™¤ä¹‹å‰çš„agentåºåˆ—
        callback_handler.clear_agent_sequence()
        
        # ğŸ”´ ä¼˜åŒ–ï¼šç®€åŒ–æ¶ˆæ¯å¤„ç†
        output = graph.invoke(
            {
                "messages": list(message_history.messages) + [HumanMessage(content=user_input)],
                "user_input": user_input,
                "config": settings,
                "callback": callback_handler,
                "recursion_count": 0,  # åˆå§‹åŒ–é€’å½’è®¡æ•°
            },
            {"recursion_limit": 15},  # å¢åŠ é€’å½’é™åˆ¶ä»¥æ”¯æŒå¤šæ­¥éª¤ä»»åŠ¡
        )
        
        # æ˜¾ç¤ºagentæ‰§è¡Œåºåˆ—
        agent_sequence = callback_handler.get_agent_sequence()
        if agent_sequence:
            st.markdown("**ğŸ¤– Agentæ‰§è¡Œé¡ºåº:**")
            agent_emojis = []
            for agent in agent_sequence:
                if "ResumeAnalyzer" in agent:
                    agent_emojis.append("ğŸ“„")
                elif "JobSearcher" in agent:
                    agent_emojis.append("ğŸ’¼")
                elif "CoverLetterGenerator" in agent:
                    agent_emojis.append("âœï¸")
                elif "WebResearcher" in agent:
                    agent_emojis.append("ğŸ”")
                elif "ChatBot" in agent:
                    agent_emojis.append("ğŸ¤–")
                else:
                    agent_emojis.append("ğŸ”„")
            
            st.markdown(" â†’ ".join([f"{emoji} {agent}" for emoji, agent in zip(agent_emojis, agent_sequence)]))
        
        # ğŸ”´ ä¼˜åŒ–ï¼šç®€åŒ–æ¶ˆæ¯æå–
        message_output = output.get("messages")[-1]
        messages_list = output.get("messages")
        message_history.clear()
        message_history.add_messages(messages_list)
        
        return message_output.content

    except Exception as exc:
        print(f"è¯¦ç»†é”™è¯¯: {exc}")
        import traceback
        traceback.print_exc()
        st.error(f"æ‰§è¡Œé”™è¯¯: {str(exc)}")
        return ":( Sorry, Some error occurred. Can you please try again?"

# æ¸…é™¤èŠå¤©åŠŸèƒ½
if st.button("æ¸…é™¤èŠå¤©"):
    st.session_state["user_query_history"] = []
    st.session_state["response_history"] = []
    message_history.clear()
    st.rerun()

streamlit_analytics.start_tracking()

# æ˜¾ç¤ºèŠå¤©ç•Œé¢
with input_section:
    options = [
        "è¯†åˆ«ä¸GenAIç›¸å…³çš„ç§‘æŠ€è¡Œä¸šæœ€æ–°è¶‹åŠ¿",
        "æŸ¥æ‰¾æ–°å…´æŠ€æœ¯åŠå…¶å¯¹å²—ä½æœºä¼šçš„å½±å“",
        "æ€»ç»“æˆ‘çš„ç®€å†",
        "æ ¹æ®æˆ‘çš„ç®€å†æŠ€èƒ½å’Œå…´è¶£ç”ŸæˆèŒä¸šè·¯å¾„å¯è§†åŒ–",
        "é˜¿é‡Œçš„GenAIç›¸å…³å²—ä½",
        "åœ¨ä¸­å›½æœç´¢GenAIç›¸å…³å²—ä½",
        "åˆ†ææˆ‘çš„ç®€å†å¹¶æ¨èåˆé€‚å²—ä½åŠç›¸å…³èŒä½åˆ—è¡¨",
        "ä¸ºæˆ‘çš„ç®€å†ç”Ÿæˆæ±‚èŒä¿¡",
    ]
    icons = ["ğŸ”", "ğŸŒ", "ğŸ“", "ğŸ“ˆ", "ğŸ’¼", "ğŸŒŸ", "âœ‰ï¸", "ğŸ§ "]

    selected_query = pills(
        "è¯·é€‰æ‹©ä¸€ä¸ªé—®é¢˜è¿›è¡ŒæŸ¥è¯¢ï¼š",
        options,
        clearable=None,
        icons=icons,
        index=st.session_state["active_option_index"],
        key="pills",
    )
    if selected_query:
        st.session_state["active_option_index"] = options.index(selected_query)

    # æ˜¾ç¤ºæ–‡æœ¬è¾“å…¥è¡¨å•
    with st.form(key="query_form", clear_on_submit=True):
        user_input_query = st.text_input(
            "è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š",
            value=(selected_query if selected_query else ""),
            placeholder="ğŸ“ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œæˆ–ä»ä¸Šæ–¹é€‰æ‹©ä¸€ä¸ªé¢„è®¾é€‰é¡¹å¼€å§‹å¯¹è¯",
            key="input",
        )
        submit_query_button = st.form_submit_button(label="å‘é€")

    if submit_query_button:
        # ğŸ”´ ä¼˜åŒ–ï¼šç®€åŒ–éªŒè¯é€»è¾‘
        if not uploaded_document:
            st.error("è¯·å…ˆä¸Šä¼ æ‚¨çš„ç®€å†ï¼Œç„¶åå†æäº¤æŸ¥è¯¢ã€‚")
        elif not api_key_tongyi and not st.secrets.get("DASHSCOPE_API_KEY", ""):
            st.error("è¯·å…ˆè¾“å…¥ DashScope API å¯†é’¥ã€‚")
        elif user_input_query:
            # ğŸ”´ ä¼˜åŒ–ï¼šç®€åŒ–æŸ¥è¯¢å¤„ç†
            chat_output = execute_chat_conversation(user_input_query, flow_graph)
            st.session_state["user_query_history"].append(user_input_query)
            st.session_state["response_history"].append(chat_output)
            st.session_state["last_input"] = user_input_query
            st.session_state["active_option_index"] = None

# æ˜¾ç¤ºèŠå¤©å†å²
if st.session_state["response_history"]:
    with conversation_container:
        for i in range(len(st.session_state["response_history"])):
            message(
                st.session_state["user_query_history"][i],
                is_user=True,
                key=str(i) + "_user",
                avatar_style="fun-emoji",
            )
            message(
                st.session_state["response_history"][i],
                key=str(i),
                avatar_style="bottts",
            )

streamlit_analytics.stop_tracking()